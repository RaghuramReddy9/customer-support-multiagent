#  Customer Support Multi-Agent Chatbot

A **multi-agent customer support assistant** built with **LangGraph, Gemini (Google GenAI), and Streamlit**.  
The bot automatically **routes queries** to the correct specialist (Billing, Tech, or General FAQ) and provides answers grounded in real support documents using **RAG (Retrieval-Augmented Generation)**.

---

<details>

<summary> Features </summary>

-  **AI Router Agent** â€“ classifies user queries into *Billing*, *Tech Support*, or *General*.
-  **RAG Specialists** â€“ each department uses its own FAQ knowledge base:
  - Billing â†’ `billing_faq.txt`
  - Tech Support â†’ `tech_faq.txt`
  - General FAQ â†’ `general_faq.txt`
-  **LangGraph Workflow** â€“ orchestrates the multi-agent escalation pipeline.
-  **Streamlit UI** â€“ clean, chat-based interface with history.
-  **Environment Config** â€“ secrets managed via `.env`.

</details>

---

<details>

<summary> Architecture </summary>

â€¢ User â†’ Frontline Agent â†’ Router Agent (Gemini) â†’ Specialist Agent (Billing / Tech / General) â†’ Response

- **Frontline Agent** â€“ greets users.  
- **Router Agent** â€“ powered by Gemini, decides which specialist to escalate to.  
- **Specialist Agents** â€“ provide grounded responses using **RAG** over department-specific FAQs.  
- **Streamlit** â€“ delivers a conversational interface.  

</details>

---

<details>

<summary> Getting Started </summary>

### 1. Clone the Repo
```bash
git clone https://github.com/RaghuramReddy9/customer-support-multiagent.git
cd customer-support-multiagent
```
### 2. Create a Virtual Environment
```bash
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
.venv\Scripts\activate      # Windows
```
### 3. Install Dependencies
```bash
pip install -r requirements.txt
```
### 4. Add API Key
Create a .env file in the project root:
```bash
GOOGLE_API_KEY=your_gemini_api_key_here
```
### 5. Run the App
```bash
streamlit run app.py
```
App will be available at â†’ http://localhost:8501

</details>

---

<details>

<summary> Project Structure </summary>

customer-support-multiagent/
â”‚â”€â”€ app.py                    # Streamlit UI
â”‚â”€â”€ multi_agent_escalation.py # LangGraph multi-agent workflow
â”‚â”€â”€ billing_faq.txt           # Billing knowledge base
â”‚â”€â”€ tech_faq.txt              # Tech support knowledge base
â”‚â”€â”€ general_faq.txt           # General FAQ knowledge base
â”‚â”€â”€ requirements.txt          # Dependencies
â”‚â”€â”€ Dockerfile                # For containerization
â”‚â”€â”€ assets/                   # Screenshots (used in README)
â”‚â”€â”€ README.md                 # Project overview
â”‚â”€â”€ .env                      # API keys (not committed)
â”‚â”€â”€ .gitignore                # Ignore venv, cache, .env, etc.

</details>

---

<details>

<summary> Screenshots </summary>

![App Screenshot](assets/demo.png)

</details>

---

<details>

<summary> Future Enhancements </summary>

â€¢ Add Agent-to-Agent collaboration (specialists ask clarifying questions).

â€¢ Deploy to Hugging Face Spaces / AWS with Docker.

â€¢ Extend knowledge bases with real company docs.

â€¢ Add analytics dashboard for routed queries (Billing vs Tech vs General).

</details>

---

<details>

<summary> Tech Stack </summary>

â€¢ LLM: Gemini 1.5 Flash (Google GenAI)

â€¢ Framework: LangGraph + LangChain

â€¢ Vector DB: Chroma + HuggingFace Embeddings

â€¢ Frontend: Streamlit

â€¢ Deployment: Docker-ready

</details>

---

<details>

<summary> Author </summary>
ðŸ‘¤ Raghuramreddy Thirumalareddy

â€¢ GitHub--> https://github.com/RaghuramReddy9

â€¢ LinkedIn--> https://www.linkedin.com/in/raghuramreddy-ai

</details>



